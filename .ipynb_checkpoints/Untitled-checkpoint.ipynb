{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c325-7373-4a0d-8c20-67749f9a22f1",
   "metadata": {},
   "source": [
    "# Data Visualisation and Communication - CA2\n",
    "\n",
    "## Online Retail Data Analysis\n",
    "\n",
    "**Student Name:** Tiago De Oliveira Freitas  \n",
    "**Student ID:** 2021406  \n",
    "**Date:** November 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Links\n",
    "\n",
    "**GitHub Repository:** https://github.com/TiagoStudent/Y4-Data-Vis-CA2-60-.git  \n",
    "**Video Presentation:** \n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Overview\n",
    "\n",
    "This notebook presents a comprehensive analysis of an Online Retail dataset from a UK-based gift wholesaler. The analysis includes data quality assessment, cleaning, exploratory data analysis (EDA), static visualisations, and an interactive dashboard to help business stakeholders understand sales patterns, product performance, and regional trends.\n",
    "\n",
    "The dataset contains transactional data including invoice numbers, product codes, descriptions, quantities, prices, timestamps, customer IDs, and countries. Our goal is to transform this raw data into actionable insights through effective visualisation and communication techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fc882-ac54-4802-893c-1d82d1fe7166",
   "metadata": {},
   "source": [
    "1. Data Quality Assessment and Cleaning\n",
    "1.1 Import Libraries and Load Data\n",
    "We begin by importing the necessary libraries for data manipulation, analysis, and visualisation. The main libraries used are:\n",
    "\n",
    "pandas: For data manipulation and analysis\n",
    "numpy: For numerical operations\n",
    "matplotlib and seaborn: For static visualisations\n",
    "plotly: For interactive visualisations and dashboard\n",
    "ipywidgets: For creating interactive dashboard controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241c874-d537-4cbb-a29e-07d7db2623d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f39e5-ae0a-45ae-9bf1-90fad3439dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_raw = pd.read_excel('OnlineRetail.xlsx')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df_raw.shape}\")\n",
    "print(f\"Number of rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Number of columns: {df_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce19f55-61b8-4002-aaa2-346ae202ce56",
   "metadata": {},
   "source": [
    "1.2 Initial Data Inspection\n",
    "Before cleaning the data, we need to understand its structure, data types, and identify potential quality issues. This initial inspection helps us make informed decisions about the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ec19e-c61f-4774-b1b0-c0c4b736e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da890dce-248b-4e73-95be-abfb8b4f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and non-null counts\n",
    "print(\"Data types and missing values:\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c4099-d6b6-4d49-9a42-ebd2743bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics\n",
    "print(\"Descriptive statistics for numerical columns:\")\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef1080-a2d3-4686-870d-6a005d567484",
   "metadata": {},
   "source": [
    "1.3 Identify Data Quality Issues\n",
    "We systematically identify various data quality issues that need to be addressed:\n",
    "\n",
    "Missing values: Columns with null or empty values\n",
    "Duplicates: Identical rows that may represent data entry errors\n",
    "Invalid values: Negative quantities or prices, which may indicate cancellations or errors\n",
    "Outliers: Extreme values that may need investigation\n",
    "Data type issues: Incorrect data types that need conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31269b51-3d1d-4682-ae92-03a9faf0cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_percentage = (df_raw.isnull().sum() / len(df_raw)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Percentage': missing_percentage.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863c2e2-4ea2-4697-ac95-612e7a4d5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates:,}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates/len(df_raw)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa117a0-f941-4cd6-983a-4edb00fbc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative quantities and prices\n",
    "print(\"\\nInvalid values analysis:\")\n",
    "print(\"=\"*50)\n",
    "negative_quantity = (df_raw['Quantity'] < 0).sum()\n",
    "zero_quantity = (df_raw['Quantity'] == 0).sum()\n",
    "negative_price = (df_raw['UnitPrice'] < 0).sum()\n",
    "zero_price = (df_raw['UnitPrice'] == 0).sum()\n",
    "\n",
    "print(f\"Rows with negative quantity: {negative_quantity:,} ({negative_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero quantity: {zero_quantity:,} ({zero_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with negative price: {negative_price:,} ({negative_price/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero price: {zero_price:,} ({zero_price/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b13dbe-1035-4d04-8237-9509ce35d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cancelled transactions (invoices starting with 'C')\n",
    "cancelled = df_raw['InvoiceNo'].astype(str).str.startswith('C').sum()\n",
    "print(f\"\\nCancelled transactions (InvoiceNo starting with 'C'): {cancelled:,} ({cancelled/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c2638-44af-46d9-93d0-edf734246a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of problematic records\n",
    "print(\"\\nSample of records with negative quantity:\")\n",
    "df_raw[df_raw['Quantity'] < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5fc9a-49fe-449e-96e2-5d04e93df125",
   "metadata": {},
   "source": [
    "1.4 Data Cleaning Process\n",
    "Based on the data quality assessment, we implement the following cleaning steps:\n",
    "\n",
    "Cleaning Decisions and Justifications:\n",
    "Remove cancelled transactions: Invoices starting with 'C' represent cancellations and should be excluded from sales analysis as they do not represent actual revenue.\n",
    "\n",
    "Remove negative quantities: Negative quantities typically indicate returns or cancellations. For this analysis focused on sales performance, we exclude these records to avoid distorting revenue calculations.\n",
    "\n",
    "Remove zero or negative prices: Products with zero or negative unit prices are likely data entry errors or special cases (e.g., samples, adjustments) that should not be included in standard sales analysis.\n",
    "\n",
    "Handle missing CustomerID: We retain records with missing CustomerID for product and country analysis, but note this limitation for customer-specific insights.\n",
    "\n",
    "Handle missing Description: We remove records with missing descriptions as product information is essential for product-level analysis.\n",
    "\n",
    "Remove duplicates: Exact duplicate rows are removed as they likely represent data entry errors.\n",
    "\n",
    "Create derived variables: We create a 'TotalPrice' column (Quantity × UnitPrice) to facilitate revenue analysis, and extract temporal features from InvoiceDate for time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3e92a-e4ff-49ae-a048-8694ebf5f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"Starting data cleaning process...\")\n",
    "print(f\"Initial dataset size: {len(df):,} rows\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088b9f6-7b36-4b49-948c-71db406552c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove cancelled transactions\n",
    "before = len(df)\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n1. Removed cancelled transactions: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd7ea5-f914-40d8-a6a7-8788f1741c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove rows with missing Description\n",
    "before = len(df)\n",
    "df = df[df['Description'].notna()]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n2. Removed rows with missing Description: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a74dbd-9142-4018-b491-8dbf2446f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove rows with negative or zero Quantity\n",
    "before = len(df)\n",
    "df = df[df['Quantity'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n3. Removed rows with negative or zero Quantity: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d517f0-4114-44ee-bebf-80e3b7f30582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove rows with negative or zero UnitPrice\n",
    "before = len(df)\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n4. Removed rows with negative or zero UnitPrice: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8f95a-4144-4ada-8115-1ec16c034349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove duplicate rows\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "removed = before - len(df)\n",
    "print(f\"\\n5. Removed duplicate rows: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e36a26-79a1-4b04-8644-96923edda1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create derived variable - TotalPrice\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "print(f\"\\n6. Created derived variable 'TotalPrice' (Quantity × UnitPrice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fd246-8f71-4bbe-809a-f4d5e6b3534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Extract temporal features from InvoiceDate\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Day'] = df['InvoiceDate'].dt.day\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')\n",
    "print(f\"\\n7. Created temporal features: Year, Month, Day, DayOfWeek, Hour, YearMonth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a73a-ff9f-4f3a-bee2-ab63acd81ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of cleaning process\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original dataset: {len(df_raw):,} rows\")\n",
    "print(f\"Cleaned dataset: {len(df):,} rows\")\n",
    "print(f\"Rows removed: {len(df_raw) - len(df):,} ({(len(df_raw) - len(df))/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Data retention rate: {len(df)/len(df_raw)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294ef12-7b9a-4d40-95ff-f4527ff6f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataset info\n",
    "print(\"\\nCleaned dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ac469-36c0-4ba0-ab30-b76671bfa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst 5 rows of cleaned dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823938d9-46ea-4969-b000-bab087da89d8",
   "metadata": {},
   "source": [
    "1.5 Data Quality After Cleaning\n",
    "After the cleaning process, we verify that the data quality has improved and document any remaining limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691c2f2-90bb-4402-8111-3dacd912cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missing values\n",
    "print(\"Remaining missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259429f6-a065-42ef-97c9-d99b1a6444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics of cleaned data\n",
    "print(\"\\nDescriptive statistics after cleaning:\")\n",
    "df[['Quantity', 'UnitPrice', 'TotalPrice']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42117d-5473-4286-b8fd-035b9e48c137",
   "metadata": {},
   "source": [
    "Limitations and Notes:\n",
    "Missing CustomerID: Approximately 25% of records still have missing CustomerID values. This limits our ability to perform customer-level analysis (e.g., customer lifetime value, retention analysis) for these transactions. However, we retain these records as they are still valuable for product and country-level analysis.\n",
    "\n",
    "Cancelled transactions excluded: By removing cancellations and returns, we focus on successful sales. However, this means we cannot analyze return patterns or cancellation reasons, which could be valuable for understanding customer satisfaction.\n",
    "\n",
    "Data period: The analysis is limited to the time period covered in the dataset. Seasonal patterns and trends should be interpreted within this context.\n",
    "\n",
    "Outliers retained: We have not removed statistical outliers (e.g., very large orders) as these may represent legitimate bulk purchases that are important for business analysis. However, they may affect some statistical measures."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
