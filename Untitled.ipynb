{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c325-7373-4a0d-8c20-67749f9a22f1",
   "metadata": {},
   "source": [
    "# Data Visualisation and Communication - CA2\n",
    "\n",
    "## Online Retail Data Analysis\n",
    "\n",
    "**Student Name:** Tiago De Oliveira Freitas  \n",
    "**Student ID:** 2021406  \n",
    "**Date:** November 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Links\n",
    "\n",
    "**GitHub Repository:** https://github.com/TiagoStudent/Y4-Data-Vis-CA2-60-.git  \n",
    "**Video Presentation:** \n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Overview\n",
    "\n",
    "This notebook presents a comprehensive analysis of an Online Retail dataset from a UK-based gift wholesaler. The analysis includes data quality assessment, cleaning, exploratory data analysis (EDA), static visualisations, and an interactive dashboard to help business stakeholders understand sales patterns, product performance, and regional trends.\n",
    "\n",
    "The dataset contains transactional data including invoice numbers, product codes, descriptions, quantities, prices, timestamps, customer IDs, and countries. Our goal is to transform this raw data into actionable insights through effective visualisation and communication techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fc882-ac54-4802-893c-1d82d1fe7166",
   "metadata": {},
   "source": [
    "1. Data Quality Assessment and Cleaning\n",
    "1.1 Import Libraries and Load Data\n",
    "We begin by importing the necessary libraries for data manipulation, analysis, and visualisation. The main libraries used are:\n",
    "\n",
    "pandas: For data manipulation and analysis\n",
    "numpy: For numerical operations\n",
    "matplotlib and seaborn: For static visualisations\n",
    "plotly: For interactive visualisations and dashboard\n",
    "ipywidgets: For creating interactive dashboard controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241c874-d537-4cbb-a29e-07d7db2623d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f39e5-ae0a-45ae-9bf1-90fad3439dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_raw = pd.read_excel('OnlineRetail.xlsx')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df_raw.shape}\")\n",
    "print(f\"Number of rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Number of columns: {df_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce19f55-61b8-4002-aaa2-346ae202ce56",
   "metadata": {},
   "source": [
    "1.2 Initial Data Inspection\n",
    "Before cleaning the data, we need to understand its structure, data types, and identify potential quality issues. This initial inspection helps us make informed decisions about the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ec19e-c61f-4774-b1b0-c0c4b736e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da890dce-248b-4e73-95be-abfb8b4f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and non-null counts\n",
    "print(\"Data types and missing values:\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c4099-d6b6-4d49-9a42-ebd2743bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics\n",
    "print(\"Descriptive statistics for numerical columns:\")\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef1080-a2d3-4686-870d-6a005d567484",
   "metadata": {},
   "source": [
    "1.3 Identify Data Quality Issues\n",
    "We systematically identify various data quality issues that need to be addressed:\n",
    "\n",
    "Missing values: Columns with null or empty values\n",
    "Duplicates: Identical rows that may represent data entry errors\n",
    "Invalid values: Negative quantities or prices, which may indicate cancellations or errors\n",
    "Outliers: Extreme values that may need investigation\n",
    "Data type issues: Incorrect data types that need conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31269b51-3d1d-4682-ae92-03a9faf0cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_percentage = (df_raw.isnull().sum() / len(df_raw)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Percentage': missing_percentage.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863c2e2-4ea2-4697-ac95-612e7a4d5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates:,}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates/len(df_raw)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa117a0-f941-4cd6-983a-4edb00fbc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative quantities and prices\n",
    "print(\"\\nInvalid values analysis:\")\n",
    "print(\"=\"*50)\n",
    "negative_quantity = (df_raw['Quantity'] < 0).sum()\n",
    "zero_quantity = (df_raw['Quantity'] == 0).sum()\n",
    "negative_price = (df_raw['UnitPrice'] < 0).sum()\n",
    "zero_price = (df_raw['UnitPrice'] == 0).sum()\n",
    "\n",
    "print(f\"Rows with negative quantity: {negative_quantity:,} ({negative_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero quantity: {zero_quantity:,} ({zero_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with negative price: {negative_price:,} ({negative_price/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero price: {zero_price:,} ({zero_price/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b13dbe-1035-4d04-8237-9509ce35d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cancelled transactions (invoices starting with 'C')\n",
    "cancelled = df_raw['InvoiceNo'].astype(str).str.startswith('C').sum()\n",
    "print(f\"\\nCancelled transactions (InvoiceNo starting with 'C'): {cancelled:,} ({cancelled/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c2638-44af-46d9-93d0-edf734246a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of problematic records\n",
    "print(\"\\nSample of records with negative quantity:\")\n",
    "df_raw[df_raw['Quantity'] < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5fc9a-49fe-449e-96e2-5d04e93df125",
   "metadata": {},
   "source": [
    "1.4 Data Cleaning Process\n",
    "Based on the data quality assessment, we implement the following cleaning steps:\n",
    "\n",
    "Cleaning Decisions and Justifications:\n",
    "Remove cancelled transactions: Invoices starting with 'C' represent cancellations and should be excluded from sales analysis as they do not represent actual revenue.\n",
    "\n",
    "Remove negative quantities: Negative quantities typically indicate returns or cancellations. For this analysis focused on sales performance, we exclude these records to avoid distorting revenue calculations.\n",
    "\n",
    "Remove zero or negative prices: Products with zero or negative unit prices are likely data entry errors or special cases (e.g., samples, adjustments) that should not be included in standard sales analysis.\n",
    "\n",
    "Handle missing CustomerID: We retain records with missing CustomerID for product and country analysis, but note this limitation for customer-specific insights.\n",
    "\n",
    "Handle missing Description: We remove records with missing descriptions as product information is essential for product-level analysis.\n",
    "\n",
    "Remove duplicates: Exact duplicate rows are removed as they likely represent data entry errors.\n",
    "\n",
    "Create derived variables: We create a 'TotalPrice' column (Quantity × UnitPrice) to facilitate revenue analysis, and extract temporal features from InvoiceDate for time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3e92a-e4ff-49ae-a048-8694ebf5f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"Starting data cleaning process...\")\n",
    "print(f\"Initial dataset size: {len(df):,} rows\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088b9f6-7b36-4b49-948c-71db406552c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove cancelled transactions\n",
    "before = len(df)\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n1. Removed cancelled transactions: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd7ea5-f914-40d8-a6a7-8788f1741c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove rows with missing Description\n",
    "before = len(df)\n",
    "df = df[df['Description'].notna()]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n2. Removed rows with missing Description: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a74dbd-9142-4018-b491-8dbf2446f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove rows with negative or zero Quantity\n",
    "before = len(df)\n",
    "df = df[df['Quantity'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n3. Removed rows with negative or zero Quantity: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d517f0-4114-44ee-bebf-80e3b7f30582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove rows with negative or zero UnitPrice\n",
    "before = len(df)\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n4. Removed rows with negative or zero UnitPrice: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8f95a-4144-4ada-8115-1ec16c034349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove duplicate rows\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "removed = before - len(df)\n",
    "print(f\"\\n5. Removed duplicate rows: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e36a26-79a1-4b04-8644-96923edda1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create derived variable - TotalPrice\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "print(f\"\\n6. Created derived variable 'TotalPrice' (Quantity × UnitPrice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fd246-8f71-4bbe-809a-f4d5e6b3534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Extract temporal features from InvoiceDate\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Day'] = df['InvoiceDate'].dt.day\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')\n",
    "print(f\"\\n7. Created temporal features: Year, Month, Day, DayOfWeek, Hour, YearMonth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a73a-ff9f-4f3a-bee2-ab63acd81ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of cleaning process\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original dataset: {len(df_raw):,} rows\")\n",
    "print(f\"Cleaned dataset: {len(df):,} rows\")\n",
    "print(f\"Rows removed: {len(df_raw) - len(df):,} ({(len(df_raw) - len(df))/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Data retention rate: {len(df)/len(df_raw)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294ef12-7b9a-4d40-95ff-f4527ff6f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataset info\n",
    "print(\"\\nCleaned dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ac469-36c0-4ba0-ab30-b76671bfa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst 5 rows of cleaned dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823938d9-46ea-4969-b000-bab087da89d8",
   "metadata": {},
   "source": [
    "1.5 Data Quality After Cleaning\n",
    "After the cleaning process, we verify that the data quality has improved and document any remaining limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691c2f2-90bb-4402-8111-3dacd912cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missing values\n",
    "print(\"Remaining missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259429f6-a065-42ef-97c9-d99b1a6444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics of cleaned data\n",
    "print(\"\\nDescriptive statistics after cleaning:\")\n",
    "df[['Quantity', 'UnitPrice', 'TotalPrice']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42117d-5473-4286-b8fd-035b9e48c137",
   "metadata": {},
   "source": [
    "Limitations and Notes:\n",
    "Missing CustomerID: Approximately 25% of records still have missing CustomerID values. This limits our ability to perform customer-level analysis (e.g., customer lifetime value, retention analysis) for these transactions. However, we retain these records as they are still valuable for product and country-level analysis.\n",
    "\n",
    "Cancelled transactions excluded: By removing cancellations and returns, we focus on successful sales. However, this means we cannot analyze return patterns or cancellation reasons, which could be valuable for understanding customer satisfaction.\n",
    "\n",
    "Data period: The analysis is limited to the time period covered in the dataset. Seasonal patterns and trends should be interpreted within this context.\n",
    "\n",
    "Outliers retained: We have not removed statistical outliers (e.g., very large orders) as these may represent legitimate bulk purchases that are important for business analysis. However, they may affect some statistical measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d1bba-7d2a-4cb0-a69e-a1325dac8a51",
   "metadata": {},
   "source": [
    "2. Exploratory Data Analysis (EDA) and Static Visualisations\n",
    "In this section, we explore the cleaned dataset through descriptive statistics and various visualisation techniques. The goal is to understand sales patterns, identify top products and customers, and discover insights about regional performance and temporal trends.\n",
    "\n",
    "2.1 Overall Business Metrics¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef70de-1e2e-43b5-9c61-a7211f48cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key business metrics\n",
    "total_revenue = df['TotalPrice'].sum()\n",
    "total_transactions = df['InvoiceNo'].nunique()\n",
    "total_products = df['StockCode'].nunique()\n",
    "total_customers = df['CustomerID'].nunique()\n",
    "total_countries = df['Country'].nunique()\n",
    "avg_order_value = total_revenue / total_transactions\n",
    "avg_items_per_transaction = df.groupby('InvoiceNo')['Quantity'].sum().mean()\n",
    "\n",
    "print(\"KEY BUSINESS METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Revenue: £{total_revenue:,.2f}\")\n",
    "print(f\"Total Transactions: {total_transactions:,}\")\n",
    "print(f\"Unique Products: {total_products:,}\")\n",
    "print(f\"Unique Customers: {total_customers:,}\")\n",
    "print(f\"Countries Served: {total_countries}\")\n",
    "print(f\"Average Order Value: £{avg_order_value:,.2f}\")\n",
    "print(f\"Average Items per Transaction: {avg_items_per_transaction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4783c2a-36eb-4162-9a46-133c76b15b62",
   "metadata": {},
   "source": [
    "2.2 Temporal Analysis: Sales Over Time¶\n",
    "Understanding how sales evolve over time is crucial for identifying trends, seasonality, and growth patterns. We use line charts for this analysis because they effectively show trends and patterns in time-series data, making it easy to spot increases, decreases, and cyclical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516ee6a-bdfe-40dc-ae8f-e3b4e0563986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily revenue trend\n",
    "daily_revenue = df.groupby(df['InvoiceDate'].dt.date)['TotalPrice'].sum().reset_index()\n",
    "daily_revenue.columns = ['Date', 'Revenue']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(daily_revenue['Date'], daily_revenue['Revenue'], linewidth=1.5, color='#2E86AB')\n",
    "plt.title('Daily Revenue Trend', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This line chart shows the daily revenue pattern over time.\")\n",
    "print(\"We can observe trends, seasonal patterns, and identify any unusual spikes or drops in sales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c6aa3-fd7d-40f9-8595-1cbd221fa601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly revenue trend\n",
    "monthly_revenue = df.groupby('YearMonth')['TotalPrice'].sum().reset_index()\n",
    "monthly_revenue['YearMonth'] = monthly_revenue['YearMonth'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_revenue['YearMonth'], monthly_revenue['TotalPrice'], \n",
    "         marker='o', linewidth=2, markersize=8, color='#A23B72')\n",
    "plt.title('Monthly Revenue Trend', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: The monthly aggregation smooths out daily fluctuations and reveals\")\n",
    "print(\"clearer trends and seasonal patterns. This helps identify peak sales periods and plan inventory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2ceac-a143-410a-8d27-f26ede203a39",
   "metadata": {},
   "source": [
    "2.3 Product Analysis: Top-Selling Products¶\n",
    "Identifying top-performing products helps prioritize inventory management and marketing efforts. We use bar charts here because they are ideal for comparing discrete categories (products) and clearly showing which items generate the most revenue or volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbc6f9-296f-4a5b-a486-1980aa312e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 products by revenue\n",
    "product_revenue = df.groupby(['StockCode', 'Description'])['TotalPrice'].sum().reset_index()\n",
    "product_revenue = product_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(product_revenue['Description'], product_revenue['TotalPrice'], color='#F18F01')\n",
    "plt.title('Top 15 Products by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Product Description', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This horizontal bar chart shows the top 15 revenue-generating products.\")\n",
    "print(\"Horizontal bars are chosen for better readability of product descriptions.\")\n",
    "print(\"These products should be prioritized in inventory management and marketing strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fbb2-b321-4160-8ec2-141aab397562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 products by quantity sold\n",
    "product_quantity = df.groupby(['StockCode', 'Description'])['Quantity'].sum().reset_index()\n",
    "product_quantity = product_quantity.sort_values('Quantity', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(product_quantity['Description'], product_quantity['Quantity'], color='#06A77D')\n",
    "plt.title('Top 15 Products by Quantity Sold', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Quantity Sold', fontsize=12)\n",
    "plt.ylabel('Product Description', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart shows products with highest sales volume.\")\n",
    "print(\"Comparing this with revenue helps identify high-volume/low-price vs. low-volume/high-price products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3266f-6f78-4052-8a38-d6071312ed7e",
   "metadata": {},
   "source": [
    "2.4 Distribution Analysis¶\n",
    "Understanding the distribution of order values and quantities helps identify typical customer behavior and detect outliers. We use histograms for this purpose as they effectively show the frequency distribution of continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968ac0e-bf5e-4408-b7b2-70b70f4e1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of order values (per invoice)\n",
    "invoice_totals = df.groupby('InvoiceNo')['TotalPrice'].sum()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(invoice_totals[invoice_totals < invoice_totals.quantile(0.95)], \n",
    "         bins=50, color='#C73E1D', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Order Values (95th percentile)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Order Value (£)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This histogram shows the distribution of order values (excluding top 5% to improve visibility).\")\n",
    "print(\"The shape reveals typical order sizes and helps identify the most common price ranges.\")\n",
    "print(f\"Median order value: £{invoice_totals.median():.2f}\")\n",
    "print(f\"Mean order value: £{invoice_totals.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba7e57-45ba-4098-9553-b94dc45bdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of quantity per transaction line\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(df[df['Quantity'] < df['Quantity'].quantile(0.95)]['Quantity'], \n",
    "         bins=50, color='#4A5859', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Quantity per Transaction Line (95th percentile)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Quantity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This histogram shows how quantities are distributed across individual transaction lines.\")\n",
    "print(\"Most transactions involve small quantities, typical of retail operations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f17aa-df31-4c98-b95d-e5e03cc491dc",
   "metadata": {},
   "source": [
    "2.5 Geographic Analysis: Sales by Country¶\n",
    "Understanding regional performance helps identify key markets and expansion opportunities. Bar charts are used to compare performance across different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c49f15-0d78-4dbf-9972-f93c907b0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 countries by revenue\n",
    "country_revenue = df.groupby('Country')['TotalPrice'].sum().reset_index()\n",
    "country_revenue = country_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(country_revenue['Country'], country_revenue['TotalPrice'], color='#5E4AE3')\n",
    "plt.title('Top 15 Countries by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Country', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart reveals which countries generate the most revenue.\")\n",
    "print(\"The UK likely dominates as it's the company's home market, but other countries\")\n",
    "print(\"represent important international markets that may warrant targeted strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd77bd-6f73-4f05-b5b9-a0bd6c0a6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue distribution: UK vs. International\n",
    "uk_revenue = df[df['Country'] == 'United Kingdom']['TotalPrice'].sum()\n",
    "international_revenue = df[df['Country'] != 'United Kingdom']['TotalPrice'].sum()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie([uk_revenue, international_revenue], \n",
    "        labels=['United Kingdom', 'International'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#2E86AB', '#F18F01'],\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "plt.title('Revenue Distribution: UK vs. International', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This pie chart shows the proportion of revenue from UK vs. international markets.\")\n",
    "print(\"Pie charts are appropriate here as we're comparing parts of a whole (total revenue).\")\n",
    "print(f\"UK Revenue: £{uk_revenue:,.2f}\")\n",
    "print(f\"International Revenue: £{international_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe904e06-cc96-4882-916d-e0515ab373b0",
   "metadata": {},
   "source": [
    "2.6 Customer Analysis¶\n",
    "Analyzing customer behavior helps identify valuable customers and understand purchasing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b8b43-e7ad-48dc-b760-5b9966fc93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 customers by revenue (excluding missing CustomerID)\n",
    "customer_revenue = df[df['CustomerID'].notna()].groupby('CustomerID')['TotalPrice'].sum().reset_index()\n",
    "customer_revenue = customer_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "customer_revenue['CustomerID'] = customer_revenue['CustomerID'].astype(int).astype(str)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(customer_revenue['CustomerID'], customer_revenue['TotalPrice'], color='#D62828')\n",
    "plt.title('Top 15 Customers by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Customer ID', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart identifies the most valuable customers by total revenue.\")\n",
    "print(\"These VIP customers may warrant special attention, loyalty programs, or personalized service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9121a-2b8a-431e-9009-1bcfa858b7cf",
   "metadata": {},
   "source": [
    "2.7 Time-of-Day and Day-of-Week Analysis¶\n",
    "Understanding when customers shop helps optimize staffing and marketing timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e10720-a3e8-4f79-a271-1526e8fcd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by hour of day\n",
    "hourly_sales = df.groupby('Hour')['TotalPrice'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_sales['Hour'], hourly_sales['TotalPrice'], color='#06A77D', edgecolor='black')\n",
    "plt.title('Revenue by Hour of Day', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Hour', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This bar chart shows revenue distribution across hours of the day.\")\n",
    "print(\"Peak hours indicate when customer activity is highest, useful for staffing and promotions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17182e69-4515-4f1d-9c30-802190fd4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by day of week\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_sales = df.groupby('DayOfWeek')['TotalPrice'].sum().reset_index()\n",
    "daily_sales['DayName'] = daily_sales['DayOfWeek'].apply(lambda x: day_names[x])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(daily_sales['DayName'], daily_sales['TotalPrice'], color='#A23B72', edgecolor='black')\n",
    "plt.title('Revenue by Day of Week', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart reveals which days of the week generate the most revenue.\")\n",
    "print(\"This pattern can inform weekly promotions and inventory planning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeb95b-07f1-4d0c-b173-c444faf17469",
   "metadata": {},
   "outputs": [],
   "source": [
    "2.8 Correlation Analysis: Price vs. Quantity¶\n",
    "A scatter plot is used to explore the relationship between unit price and quantity sold, helping identify pricing patterns and potential price sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84244712-f70f-4891-831e-5f1e5dcf11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: UnitPrice vs Quantity (sample for visibility)\n",
    "sample_df = df.sample(n=min(5000, len(df)), random_state=42)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(sample_df['UnitPrice'], sample_df['Quantity'], \n",
    "            alpha=0.5, s=30, c='#5E4AE3', edgecolors='black', linewidth=0.5)\n",
    "plt.title('Relationship between Unit Price and Quantity (Sample)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Unit Price (£)', fontsize=12)\n",
    "plt.ylabel('Quantity', fontsize=12)\n",
    "plt.xlim(0, sample_df['UnitPrice'].quantile(0.95))\n",
    "plt.ylim(0, sample_df['Quantity'].quantile(0.95))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This scatter plot explores whether there's a relationship between price and quantity.\")\n",
    "print(\"Scatter plots are ideal for identifying correlations or patterns between two continuous variables.\")\n",
    "print(\"The pattern can reveal price sensitivity or bulk purchasing behavior.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
