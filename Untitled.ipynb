{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec02c325-7373-4a0d-8c20-67749f9a22f1",
   "metadata": {},
   "source": [
    "# Data Visualisation and Communication - CA2\n",
    "\n",
    "## Online Retail Data Analysis\n",
    "\n",
    "**Student Name:** Tiago De Oliveira Freitas  \n",
    "**Student ID:** 2021406  \n",
    "**Date:** November 2025\n",
    "\n",
    "---\n",
    "\n",
    "### Links\n",
    "\n",
    "**GitHub Repository:** https://github.com/TiagoStudent/Y4-Data-Vis-CA2-60-.git  \n",
    "**Video Presentation:** \n",
    "\n",
    "---\n",
    "\n",
    "### Assignment Overview\n",
    "\n",
    "This notebook presents a comprehensive analysis of an Online Retail dataset from a UK-based gift wholesaler. The analysis includes data quality assessment, cleaning, exploratory data analysis (EDA), static visualisations, and an interactive dashboard to help business stakeholders understand sales patterns, product performance, and regional trends.\n",
    "\n",
    "The dataset contains transactional data including invoice numbers, product codes, descriptions, quantities, prices, timestamps, customer IDs, and countries. Our goal is to transform this raw data into actionable insights through effective visualisation and communication techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67fc882-ac54-4802-893c-1d82d1fe7166",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 1. Data Quality Assessment and Cleaning\n",
    "\n",
    "### 1.1 Import Libraries and Load Data\n",
    "\n",
    "We begin by importing the necessary libraries for data manipulation, analysis, and visualisation. The main libraries used are:\n",
    "\n",
    "- **pandas**: For data manipulation and analysis\n",
    "- **numpy**: For numerical operations\n",
    "- **matplotlib** and **seaborn**: For static visualisations\n",
    "- **plotly**: For interactive visualisations and dashboard\n",
    "- **ipywidgets**: For creating interactive dashboard controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5241c874-d537-4cbb-a29e-07d7db2623d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure display settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655f39e5-ae0a-45ae-9bf1-90fad3439dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_raw = pd.read_excel('OnlineRetail.xlsx')\n",
    "\n",
    "# Display basic information\n",
    "print(\"Dataset loaded successfully!\")\n",
    "print(f\"\\nDataset shape: {df_raw.shape}\")\n",
    "print(f\"Number of rows: {df_raw.shape[0]:,}\")\n",
    "print(f\"Number of columns: {df_raw.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce19f55-61b8-4002-aaa2-346ae202ce56",
   "metadata": {},
   "source": [
    "### 1.2 Initial Data Inspection\n",
    "\n",
    "Before cleaning the data, we need to understand its structure, data types, and identify potential quality issues. This initial inspection helps us make informed decisions about the cleaning process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659ec19e-c61f-4774-b1b0-c0c4b736e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 10 rows of the dataset:\")\n",
    "df_raw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da890dce-248b-4e73-95be-abfb8b4f899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data types and non-null counts\n",
    "print(\"Data types and missing values:\")\n",
    "df_raw.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c4099-d6b6-4d49-9a42-ebd2743bf120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics\n",
    "print(\"Descriptive statistics for numerical columns:\")\n",
    "df_raw.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ef1080-a2d3-4686-870d-6a005d567484",
   "metadata": {},
   "source": [
    "### 1.3 Identify Data Quality Issues\n",
    "\n",
    "We systematically identify various data quality issues that need to be addressed:\n",
    "\n",
    "1. **Missing values**: Columns with null or empty values\n",
    "2. **Duplicates**: Identical rows that may represent data entry errors\n",
    "3. **Invalid values**: Negative quantities or prices, which may indicate cancellations or errors\n",
    "4. **Outliers**: Extreme values that may need investigation\n",
    "5. **Data type issues**: Incorrect data types that need conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31269b51-3d1d-4682-ae92-03a9faf0cce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values analysis:\")\n",
    "print(\"=\"*50)\n",
    "missing_values = df_raw.isnull().sum()\n",
    "missing_percentage = (df_raw.isnull().sum() / len(df_raw)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Column': missing_values.index,\n",
    "    'Missing Count': missing_values.values,\n",
    "    'Percentage': missing_percentage.values\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(missing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1863c2e2-4ea2-4697-ac95-612e7a4d5d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicate rows\n",
    "duplicates = df_raw.duplicated().sum()\n",
    "print(f\"\\nNumber of duplicate rows: {duplicates:,}\")\n",
    "print(f\"Percentage of duplicates: {(duplicates/len(df_raw)*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa117a0-f941-4cd6-983a-4edb00fbc9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for negative quantities and prices\n",
    "print(\"\\nInvalid values analysis:\")\n",
    "print(\"=\"*50)\n",
    "negative_quantity = (df_raw['Quantity'] < 0).sum()\n",
    "zero_quantity = (df_raw['Quantity'] == 0).sum()\n",
    "negative_price = (df_raw['UnitPrice'] < 0).sum()\n",
    "zero_price = (df_raw['UnitPrice'] == 0).sum()\n",
    "\n",
    "print(f\"Rows with negative quantity: {negative_quantity:,} ({negative_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero quantity: {zero_quantity:,} ({zero_quantity/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with negative price: {negative_price:,} ({negative_price/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Rows with zero price: {zero_price:,} ({zero_price/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b13dbe-1035-4d04-8237-9509ce35d1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for cancelled transactions (invoices starting with 'C')\n",
    "cancelled = df_raw['InvoiceNo'].astype(str).str.startswith('C').sum()\n",
    "print(f\"\\nCancelled transactions (InvoiceNo starting with 'C'): {cancelled:,} ({cancelled/len(df_raw)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94c2638-44af-46d9-93d0-edf734246a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample of problematic records\n",
    "print(\"\\nSample of records with negative quantity:\")\n",
    "df_raw[df_raw['Quantity'] < 0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce5fc9a-49fe-449e-96e2-5d04e93df125",
   "metadata": {},
   "source": [
    "### 1.4 Data Cleaning Process\n",
    "\n",
    "Based on the data quality assessment, we implement the following cleaning steps:\n",
    "\n",
    "#### **Cleaning Decisions and Justifications:**\n",
    "\n",
    "1. **Remove cancelled transactions**: Invoices starting with 'C' represent cancellations and should be excluded from sales analysis as they do not represent actual revenue.\n",
    "\n",
    "2. **Remove negative quantities**: Negative quantities typically indicate returns or cancellations. For this analysis focused on sales performance, we exclude these records to avoid distorting revenue calculations.\n",
    "\n",
    "3. **Remove zero or negative prices**: Products with zero or negative unit prices are likely data entry errors or special cases (e.g., samples, adjustments) that should not be included in standard sales analysis.\n",
    "\n",
    "4. **Handle missing CustomerID**: We retain records with missing CustomerID for product and country analysis, but note this limitation for customer-specific insights.\n",
    "\n",
    "5. **Handle missing Description**: We remove records with missing descriptions as product information is essential for product-level analysis.\n",
    "\n",
    "6. **Remove duplicates**: Exact duplicate rows are removed as they likely represent data entry errors.\n",
    "\n",
    "7. **Create derived variables**: We create a 'TotalPrice' column (Quantity × UnitPrice) to facilitate revenue analysis, and extract temporal features from InvoiceDate for time-series analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e3e92a-e4ff-49ae-a048-8694ebf5f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for cleaning\n",
    "df = df_raw.copy()\n",
    "\n",
    "print(\"Starting data cleaning process...\")\n",
    "print(f\"Initial dataset size: {len(df):,} rows\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8088b9f6-7b36-4b49-948c-71db406552c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Remove cancelled transactions\n",
    "before = len(df)\n",
    "df = df[~df['InvoiceNo'].astype(str).str.startswith('C')]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n1. Removed cancelled transactions: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd7ea5-f914-40d8-a6a7-8788f1741c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Remove rows with missing Description\n",
    "before = len(df)\n",
    "df = df[df['Description'].notna()]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n2. Removed rows with missing Description: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a74dbd-9142-4018-b491-8dbf2446f8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Remove rows with negative or zero Quantity\n",
    "before = len(df)\n",
    "df = df[df['Quantity'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n3. Removed rows with negative or zero Quantity: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d517f0-4114-44ee-bebf-80e3b7f30582",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Remove rows with negative or zero UnitPrice\n",
    "before = len(df)\n",
    "df = df[df['UnitPrice'] > 0]\n",
    "removed = before - len(df)\n",
    "print(f\"\\n4. Removed rows with negative or zero UnitPrice: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f8f95a-4144-4ada-8115-1ec16c034349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Remove duplicate rows\n",
    "before = len(df)\n",
    "df = df.drop_duplicates()\n",
    "removed = before - len(df)\n",
    "print(f\"\\n5. Removed duplicate rows: {removed:,} rows\")\n",
    "print(f\"   Remaining: {len(df):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e36a26-79a1-4b04-8644-96923edda1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Create derived variable - TotalPrice\n",
    "df['TotalPrice'] = df['Quantity'] * df['UnitPrice']\n",
    "print(f\"\\n6. Created derived variable 'TotalPrice' (Quantity × UnitPrice)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1fd246-8f71-4bbe-809a-f4d5e6b3534d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Extract temporal features from InvoiceDate\n",
    "df['Year'] = df['InvoiceDate'].dt.year\n",
    "df['Month'] = df['InvoiceDate'].dt.month\n",
    "df['Day'] = df['InvoiceDate'].dt.day\n",
    "df['DayOfWeek'] = df['InvoiceDate'].dt.dayofweek\n",
    "df['Hour'] = df['InvoiceDate'].dt.hour\n",
    "df['YearMonth'] = df['InvoiceDate'].dt.to_period('M')\n",
    "print(f\"\\n7. Created temporal features: Year, Month, Day, DayOfWeek, Hour, YearMonth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e952a73a-ff9f-4f3a-bee2-ab63acd81ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of cleaning process\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original dataset: {len(df_raw):,} rows\")\n",
    "print(f\"Cleaned dataset: {len(df):,} rows\")\n",
    "print(f\"Rows removed: {len(df_raw) - len(df):,} ({(len(df_raw) - len(df))/len(df_raw)*100:.2f}%)\")\n",
    "print(f\"Data retention rate: {len(df)/len(df_raw)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294ef12-7b9a-4d40-95ff-f4527ff6f42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display cleaned dataset info\n",
    "print(\"\\nCleaned dataset information:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539ac469-36c0-4ba0-ab30-b76671bfa96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows of cleaned data\n",
    "print(\"\\nFirst 5 rows of cleaned dataset:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823938d9-46ea-4969-b000-bab087da89d8",
   "metadata": {},
   "source": [
    "### 1.5 Data Quality After Cleaning\n",
    "\n",
    "After the cleaning process, we verify that the data quality has improved and document any remaining limitations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c691c2f2-90bb-4402-8111-3dacd912cb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check remaining missing values\n",
    "print(\"Remaining missing values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259429f6-a065-42ef-97c9-d99b1a6444dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display descriptive statistics of cleaned data\n",
    "print(\"\\nDescriptive statistics after cleaning:\")\n",
    "df[['Quantity', 'UnitPrice', 'TotalPrice']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d42117d-5473-4286-b8fd-035b9e48c137",
   "metadata": {},
   "source": [
    "#### **Limitations and Notes:**\n",
    "\n",
    "1. **Missing CustomerID**: Approximately 25% of records still have missing CustomerID values. This limits our ability to perform customer-level analysis (e.g., customer lifetime value, retention analysis) for these transactions. However, we retain these records as they are still valuable for product and country-level analysis.\n",
    "\n",
    "2. **Cancelled transactions excluded**: By removing cancellations and returns, we focus on successful sales. However, this means we cannot analyze return patterns or cancellation reasons, which could be valuable for understanding customer satisfaction.\n",
    "\n",
    "3. **Data period**: The analysis is limited to the time period covered in the dataset. Seasonal patterns and trends should be interpreted within this context.\n",
    "\n",
    "4. **Outliers retained**: We have not removed statistical outliers (e.g., very large orders) as these may represent legitimate bulk purchases that are important for business analysis. However, they may affect some statistical measures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4d1bba-7d2a-4cb0-a69e-a1325dac8a51",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 2. Exploratory Data Analysis (EDA) and Static Visualisations\n",
    "\n",
    "In this section, we explore the cleaned dataset through descriptive statistics and various visualisation techniques. The goal is to understand sales patterns, identify top products and customers, and discover insights about regional performance and temporal trends.\n",
    "\n",
    "### 2.1 Overall Business Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ef70de-1e2e-43b5-9c61-a7211f48cb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate key business metrics\n",
    "total_revenue = df['TotalPrice'].sum()\n",
    "total_transactions = df['InvoiceNo'].nunique()\n",
    "total_products = df['StockCode'].nunique()\n",
    "total_customers = df['CustomerID'].nunique()\n",
    "total_countries = df['Country'].nunique()\n",
    "avg_order_value = total_revenue / total_transactions\n",
    "avg_items_per_transaction = df.groupby('InvoiceNo')['Quantity'].sum().mean()\n",
    "\n",
    "print(\"KEY BUSINESS METRICS\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Total Revenue: £{total_revenue:,.2f}\")\n",
    "print(f\"Total Transactions: {total_transactions:,}\")\n",
    "print(f\"Unique Products: {total_products:,}\")\n",
    "print(f\"Unique Customers: {total_customers:,}\")\n",
    "print(f\"Countries Served: {total_countries}\")\n",
    "print(f\"Average Order Value: £{avg_order_value:,.2f}\")\n",
    "print(f\"Average Items per Transaction: {avg_items_per_transaction:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4783c2a-36eb-4162-9a46-133c76b15b62",
   "metadata": {},
   "source": [
    "### 2.2 Temporal Analysis: Sales Over Time\n",
    "\n",
    "Understanding how sales evolve over time is crucial for identifying trends, seasonality, and growth patterns. We use **line charts** for this analysis because they effectively show trends and patterns in time-series data, making it easy to spot increases, decreases, and cyclical patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8516ee6a-bdfe-40dc-ae8f-e3b4e0563986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily revenue trend\n",
    "daily_revenue = df.groupby(df['InvoiceDate'].dt.date)['TotalPrice'].sum().reset_index()\n",
    "daily_revenue.columns = ['Date', 'Revenue']\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(daily_revenue['Date'], daily_revenue['Revenue'], linewidth=1.5, color='#2E86AB')\n",
    "plt.title('Daily Revenue Trend', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This line chart shows the daily revenue pattern over time.\")\n",
    "print(\"We can observe trends, seasonal patterns, and identify any unusual spikes or drops in sales.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c6aa3-fd7d-40f9-8595-1cbd221fa601",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monthly revenue trend\n",
    "monthly_revenue = df.groupby('YearMonth')['TotalPrice'].sum().reset_index()\n",
    "monthly_revenue['YearMonth'] = monthly_revenue['YearMonth'].astype(str)\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(monthly_revenue['YearMonth'], monthly_revenue['TotalPrice'], \n",
    "         marker='o', linewidth=2, markersize=8, color='#A23B72')\n",
    "plt.title('Monthly Revenue Trend', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Month', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: The monthly aggregation smooths out daily fluctuations and reveals\")\n",
    "print(\"clearer trends and seasonal patterns. This helps identify peak sales periods and plan inventory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c2ceac-a143-410a-8d27-f26ede203a39",
   "metadata": {},
   "source": [
    "### 2.3 Product Analysis: Top-Selling Products\n",
    "\n",
    "Identifying top-performing products helps prioritize inventory management and marketing efforts. We use **bar charts** here because they are ideal for comparing discrete categories (products) and clearly showing which items generate the most revenue or volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adbc6f9-296f-4a5b-a486-1980aa312e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 products by revenue\n",
    "product_revenue = df.groupby(['StockCode', 'Description'])['TotalPrice'].sum().reset_index()\n",
    "product_revenue = product_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(product_revenue['Description'], product_revenue['TotalPrice'], color='#F18F01')\n",
    "plt.title('Top 15 Products by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Product Description', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This horizontal bar chart shows the top 15 revenue-generating products.\")\n",
    "print(\"Horizontal bars are chosen for better readability of product descriptions.\")\n",
    "print(\"These products should be prioritized in inventory management and marketing strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e9fbb2-b321-4160-8ec2-141aab397562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 products by quantity sold\n",
    "product_quantity = df.groupby(['StockCode', 'Description'])['Quantity'].sum().reset_index()\n",
    "product_quantity = product_quantity.sort_values('Quantity', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(product_quantity['Description'], product_quantity['Quantity'], color='#06A77D')\n",
    "plt.title('Top 15 Products by Quantity Sold', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Quantity Sold', fontsize=12)\n",
    "plt.ylabel('Product Description', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart shows products with highest sales volume.\")\n",
    "print(\"Comparing this with revenue helps identify high-volume/low-price vs. low-volume/high-price products.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a3266f-6f78-4052-8a38-d6071312ed7e",
   "metadata": {},
   "source": [
    "### 2.4 Distribution Analysis\n",
    "\n",
    "Understanding the distribution of order values and quantities helps identify typical customer behavior and detect outliers. We use **histograms** for this purpose as they effectively show the frequency distribution of continuous variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968ac0e-bf5e-4408-b7b2-70b70f4e1b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of order values (per invoice)\n",
    "invoice_totals = df.groupby('InvoiceNo')['TotalPrice'].sum()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(invoice_totals[invoice_totals < invoice_totals.quantile(0.95)], \n",
    "         bins=50, color='#C73E1D', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Order Values (95th percentile)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Order Value (£)', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This histogram shows the distribution of order values (excluding top 5% to improve visibility).\")\n",
    "print(\"The shape reveals typical order sizes and helps identify the most common price ranges.\")\n",
    "print(f\"Median order value: £{invoice_totals.median():.2f}\")\n",
    "print(f\"Mean order value: £{invoice_totals.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ba7e57-45ba-4098-9553-b94dc45bdd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of quantity per transaction line\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.hist(df[df['Quantity'] < df['Quantity'].quantile(0.95)]['Quantity'], \n",
    "         bins=50, color='#4A5859', edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Quantity per Transaction Line (95th percentile)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Quantity', fontsize=12)\n",
    "plt.ylabel('Frequency', fontsize=12)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This histogram shows how quantities are distributed across individual transaction lines.\")\n",
    "print(\"Most transactions involve small quantities, typical of retail operations.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78f17aa-df31-4c98-b95d-e5e03cc491dc",
   "metadata": {},
   "source": [
    "### 2.5 Geographic Analysis: Sales by Country\n",
    "\n",
    "Understanding regional performance helps identify key markets and expansion opportunities. Bar charts are used to compare performance across different countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c49f15-0d78-4dbf-9972-f93c907b0c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 countries by revenue\n",
    "country_revenue = df.groupby('Country')['TotalPrice'].sum().reset_index()\n",
    "country_revenue = country_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(country_revenue['Country'], country_revenue['TotalPrice'], color='#5E4AE3')\n",
    "plt.title('Top 15 Countries by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Country', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart reveals which countries generate the most revenue.\")\n",
    "print(\"The UK likely dominates as it's the company's home market, but other countries\")\n",
    "print(\"represent important international markets that may warrant targeted strategies.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fd77bd-6f73-4f05-b5b9-a0bd6c0a6bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Revenue distribution: UK vs. International\n",
    "uk_revenue = df[df['Country'] == 'United Kingdom']['TotalPrice'].sum()\n",
    "international_revenue = df[df['Country'] != 'United Kingdom']['TotalPrice'].sum()\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie([uk_revenue, international_revenue], \n",
    "        labels=['United Kingdom', 'International'],\n",
    "        autopct='%1.1f%%',\n",
    "        colors=['#2E86AB', '#F18F01'],\n",
    "        startangle=90,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "plt.title('Revenue Distribution: UK vs. International', fontsize=16, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This pie chart shows the proportion of revenue from UK vs. international markets.\")\n",
    "print(\"Pie charts are appropriate here as we're comparing parts of a whole (total revenue).\")\n",
    "print(f\"UK Revenue: £{uk_revenue:,.2f}\")\n",
    "print(f\"International Revenue: £{international_revenue:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe904e06-cc96-4882-916d-e0515ab373b0",
   "metadata": {},
   "source": [
    "### 2.6 Customer Analysis\n",
    "\n",
    "Analyzing customer behavior helps identify valuable customers and understand purchasing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01b8b43-e7ad-48dc-b760-5b9966fc93e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top 15 customers by revenue (excluding missing CustomerID)\n",
    "customer_revenue = df[df['CustomerID'].notna()].groupby('CustomerID')['TotalPrice'].sum().reset_index()\n",
    "customer_revenue = customer_revenue.sort_values('TotalPrice', ascending=False).head(15)\n",
    "customer_revenue['CustomerID'] = customer_revenue['CustomerID'].astype(int).astype(str)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(customer_revenue['CustomerID'], customer_revenue['TotalPrice'], color='#D62828')\n",
    "plt.title('Top 15 Customers by Revenue', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Revenue (£)', fontsize=12)\n",
    "plt.ylabel('Customer ID', fontsize=12)\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart identifies the most valuable customers by total revenue.\")\n",
    "print(\"These VIP customers may warrant special attention, loyalty programs, or personalized service.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a9121a-2b8a-431e-9009-1bcfa858b7cf",
   "metadata": {},
   "source": [
    "### 2.7 Time-of-Day and Day-of-Week Analysis\n",
    "\n",
    "Understanding when customers shop helps optimize staffing and marketing timing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e10720-a3e8-4f79-a271-1526e8fcd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by hour of day\n",
    "hourly_sales = df.groupby('Hour')['TotalPrice'].sum().reset_index()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(hourly_sales['Hour'], hourly_sales['TotalPrice'], color='#06A77D', edgecolor='black')\n",
    "plt.title('Revenue by Hour of Day', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Hour', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This bar chart shows revenue distribution across hours of the day.\")\n",
    "print(\"Peak hours indicate when customer activity is highest, useful for staffing and promotions.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17182e69-4515-4f1d-9c30-802190fd4709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sales by day of week\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "daily_sales = df.groupby('DayOfWeek')['TotalPrice'].sum().reset_index()\n",
    "daily_sales['DayName'] = daily_sales['DayOfWeek'].apply(lambda x: day_names[x])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(daily_sales['DayName'], daily_sales['TotalPrice'], color='#A23B72', edgecolor='black')\n",
    "plt.title('Revenue by Day of Week', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Revenue (£)', fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This chart reveals which days of the week generate the most revenue.\")\n",
    "print(\"This pattern can inform weekly promotions and inventory planning.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebeb95b-07f1-4d0c-b173-c444faf17469",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2.8 Correlation Analysis: Price vs. Quantity\n",
    "\n",
    "A **scatter plot** is used to explore the relationship between unit price and quantity sold, helping identify pricing patterns and potential price sensitivity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84244712-f70f-4891-831e-5f1e5dcf11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: UnitPrice vs Quantity (sample for visibility)\n",
    "sample_df = df.sample(n=min(5000, len(df)), random_state=42)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(sample_df['UnitPrice'], sample_df['Quantity'], \n",
    "            alpha=0.5, s=30, c='#5E4AE3', edgecolors='black', linewidth=0.5)\n",
    "plt.title('Relationship between Unit Price and Quantity (Sample)', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Unit Price (£)', fontsize=12)\n",
    "plt.ylabel('Quantity', fontsize=12)\n",
    "plt.xlim(0, sample_df['UnitPrice'].quantile(0.95))\n",
    "plt.ylim(0, sample_df['Quantity'].quantile(0.95))\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation: This scatter plot explores whether there's a relationship between price and quantity.\")\n",
    "print(\"Scatter plots are ideal for identifying correlations or patterns between two continuous variables.\")\n",
    "print(\"The pattern can reveal price sensitivity or bulk purchasing behavior.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4edd85e-2d6c-43f4-af12-2f35ffe95483",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 3. Interactive Dashboard\n",
    "\n",
    "### 3.1 Dashboard Overview\n",
    "\n",
    "#### **Intended Audience:**\n",
    "This dashboard is designed for **business managers and executives** who need to quickly understand sales performance, identify trends, and make data-driven decisions. The interface is intuitive and requires no technical expertise.\n",
    "\n",
    "#### **Dashboard Structure:**\n",
    "The dashboard is organized in a **3-column by 2-row grid layout** containing:\n",
    "\n",
    "**Row 1 - Key Metrics and Filters:**\n",
    "- Column 1: Interactive filters (date range, country, minimum order value)\n",
    "- Column 2: Key performance indicators (KPIs)\n",
    "- Column 3: Revenue trend over time\n",
    "\n",
    "**Row 2 - Detailed Analysis:**\n",
    "- Column 1: Top products by revenue\n",
    "- Column 2: Geographic distribution\n",
    "- Column 3: Time-based patterns\n",
    "\n",
    "#### **Filter Justifications:**\n",
    "\n",
    "1. **Date Range Filter**: Allows managers to focus on specific time periods (e.g., quarters, promotional periods) and compare performance across different timeframes. This is essential for identifying seasonal trends and evaluating campaign effectiveness.\n",
    "\n",
    "2. **Country Selection**: Enables regional managers to focus on their markets or compare performance across countries. This supports market-specific strategy development and resource allocation.\n",
    "\n",
    "3. **Minimum Order Value**: Helps filter out small transactions to focus on significant orders, useful for B2B analysis or identifying wholesale vs. retail patterns.\n",
    "\n",
    "#### **Visualisation Choices:**\n",
    "\n",
    "- **Line charts** for temporal trends: Best for showing changes over time and identifying patterns\n",
    "- **Bar charts** for categorical comparisons: Clear comparison of products, countries, or time periods\n",
    "- **KPI cards** for key metrics: Immediate visibility of critical business numbers\n",
    "- **Interactive elements**: Plotly is used for its interactivity (hover, zoom, pan) which enhances exploration\n",
    "\n",
    "### 3.2 Dashboard Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5570a271-0be2-4aca-885f-5acae8489363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for dashboard\n",
    "# Get date range\n",
    "min_date = df['InvoiceDate'].min().date()\n",
    "max_date = df['InvoiceDate'].max().date()\n",
    "\n",
    "# Get list of countries\n",
    "countries = ['All'] + sorted(df['Country'].unique().tolist())\n",
    "\n",
    "print(f\"Dashboard data prepared\")\n",
    "print(f\"Date range: {min_date} to {max_date}\")\n",
    "print(f\"Number of countries: {len(countries)-1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c177439a-ebfe-48b2-9041-6eacf0dfdd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "date_range = widgets.DatePicker(\n",
    "    description='Start Date:',\n",
    "    value=min_date,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "end_date_range = widgets.DatePicker(\n",
    "    description='End Date:',\n",
    "    value=max_date,\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "country_filter = widgets.Dropdown(\n",
    "    options=countries,\n",
    "    value='All',\n",
    "    description='Country:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "min_order_value = widgets.FloatSlider(\n",
    "    value=0,\n",
    "    min=0,\n",
    "    max=1000,\n",
    "    step=50,\n",
    "    description='Min Order Value (£):',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.0f',\n",
    "    style={'description_width': 'initial'}\n",
    ")\n",
    "\n",
    "update_button = widgets.Button(\n",
    "    description='Update Dashboard',\n",
    "    button_style='success',\n",
    "    tooltip='Click to update visualisations',\n",
    "    icon='refresh'\n",
    ")\n",
    "\n",
    "output = widgets.Output()\n",
    "\n",
    "print(\"Interactive widgets created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca665d6-12dd-4122-af10-f3eb3256813f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dashboard update function\n",
    "def update_dashboard(b):\n",
    "    with output:\n",
    "        output.clear_output(wait=True)\n",
    "        \n",
    "        # Filter data based on selections\n",
    "        filtered_df = df.copy()\n",
    "        \n",
    "        # Apply date filter\n",
    "        start = pd.Timestamp(date_range.value)\n",
    "        end = pd.Timestamp(end_date_range.value) + pd.Timedelta(days=1)\n",
    "        filtered_df = filtered_df[(filtered_df['InvoiceDate'] >= start) & \n",
    "                                  (filtered_df['InvoiceDate'] < end)]\n",
    "        \n",
    "        # Apply country filter\n",
    "        if country_filter.value != 'All':\n",
    "            filtered_df = filtered_df[filtered_df['Country'] == country_filter.value]\n",
    "        \n",
    "        # Apply minimum order value filter\n",
    "        invoice_totals = filtered_df.groupby('InvoiceNo')['TotalPrice'].sum()\n",
    "        valid_invoices = invoice_totals[invoice_totals >= min_order_value.value].index\n",
    "        filtered_df = filtered_df[filtered_df['InvoiceNo'].isin(valid_invoices)]\n",
    "        \n",
    "        if len(filtered_df) == 0:\n",
    "            print(\"No data available for the selected filters. Please adjust your selections.\")\n",
    "            return\n",
    "        \n",
    "        # Calculate KPIs\n",
    "        kpi_revenue = filtered_df['TotalPrice'].sum()\n",
    "        kpi_transactions = filtered_df['InvoiceNo'].nunique()\n",
    "        kpi_customers = filtered_df['CustomerID'].nunique()\n",
    "        kpi_avg_order = kpi_revenue / kpi_transactions if kpi_transactions > 0 else 0\n",
    "        \n",
    "        # Create subplots\n",
    "        fig = make_subplots(\n",
    "            rows=2, cols=3,\n",
    "            subplot_titles=(\n",
    "                'Key Performance Indicators',\n",
    "                'Revenue Trend Over Time',\n",
    "                'Top 10 Products by Revenue',\n",
    "                'Revenue by Country (Top 10)',\n",
    "                'Revenue by Day of Week',\n",
    "                'Revenue by Hour of Day'\n",
    "            ),\n",
    "            specs=[\n",
    "                [{'type': 'indicator'}, {'type': 'scatter'}, {'type': 'bar'}],\n",
    "                [{'type': 'bar'}, {'type': 'bar'}, {'type': 'bar'}]\n",
    "            ],\n",
    "            vertical_spacing=0.15,\n",
    "            horizontal_spacing=0.1\n",
    "        )\n",
    "        \n",
    "        # Row 1, Col 1: KPIs as indicators\n",
    "        fig.add_trace(\n",
    "            go.Indicator(\n",
    "                mode=\"number\",\n",
    "                value=kpi_revenue,\n",
    "                title={\"text\": f\"Total Revenue<br>£{kpi_revenue:,.0f}<br><br>Transactions: {kpi_transactions:,}<br>Customers: {kpi_customers:,}<br>Avg Order: £{kpi_avg_order:.2f}\"},\n",
    "                domain={'x': [0, 1], 'y': [0, 1]}\n",
    "            ),\n",
    "            row=1, col=1\n",
    "        )\n",
    "        \n",
    "        # Row 1, Col 2: Revenue trend\n",
    "        daily_rev = filtered_df.groupby(filtered_df['InvoiceDate'].dt.date)['TotalPrice'].sum().reset_index()\n",
    "        daily_rev.columns = ['Date', 'Revenue']\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=daily_rev['Date'],\n",
    "                y=daily_rev['Revenue'],\n",
    "                mode='lines',\n",
    "                name='Revenue',\n",
    "                line=dict(color='#2E86AB', width=2)\n",
    "            ),\n",
    "            row=1, col=2\n",
    "        )\n",
    "        \n",
    "        # Row 1, Col 3: Top products\n",
    "        top_products = filtered_df.groupby('Description')['TotalPrice'].sum().nlargest(10).reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                y=top_products['Description'],\n",
    "                x=top_products['TotalPrice'],\n",
    "                orientation='h',\n",
    "                name='Revenue',\n",
    "                marker=dict(color='#F18F01')\n",
    "            ),\n",
    "            row=1, col=3\n",
    "        )\n",
    "        \n",
    "        # Row 2, Col 1: Top countries\n",
    "        top_countries = filtered_df.groupby('Country')['TotalPrice'].sum().nlargest(10).reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                y=top_countries['Country'],\n",
    "                x=top_countries['TotalPrice'],\n",
    "                orientation='h',\n",
    "                name='Revenue',\n",
    "                marker=dict(color='#5E4AE3')\n",
    "            ),\n",
    "            row=2, col=1\n",
    "        )\n",
    "        \n",
    "        # Row 2, Col 2: Day of week\n",
    "        day_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "        dow_rev = filtered_df.groupby('DayOfWeek')['TotalPrice'].sum().reset_index()\n",
    "        dow_rev['DayName'] = dow_rev['DayOfWeek'].apply(lambda x: day_names[x])\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=dow_rev['DayName'],\n",
    "                y=dow_rev['TotalPrice'],\n",
    "                name='Revenue',\n",
    "                marker=dict(color='#A23B72')\n",
    "            ),\n",
    "            row=2, col=2\n",
    "        )\n",
    "        \n",
    "        # Row 2, Col 3: Hour of day\n",
    "        hour_rev = filtered_df.groupby('Hour')['TotalPrice'].sum().reset_index()\n",
    "        fig.add_trace(\n",
    "            go.Bar(\n",
    "                x=hour_rev['Hour'],\n",
    "                y=hour_rev['TotalPrice'],\n",
    "                name='Revenue',\n",
    "                marker=dict(color='#06A77D')\n",
    "            ),\n",
    "            row=2, col=3\n",
    "        )\n",
    "        \n",
    "        # Update layout\n",
    "        fig.update_layout(\n",
    "            height=900,\n",
    "            showlegend=False,\n",
    "            title_text=f\"Online Retail Sales Dashboard - {len(filtered_df):,} records\",\n",
    "            title_font_size=20\n",
    "        )\n",
    "        \n",
    "        # Update axes labels\n",
    "        fig.update_xaxes(title_text=\"Date\", row=1, col=2)\n",
    "        fig.update_yaxes(title_text=\"Revenue (£)\", row=1, col=2)\n",
    "        \n",
    "        fig.update_xaxes(title_text=\"Revenue (£)\", row=1, col=3)\n",
    "        fig.update_xaxes(title_text=\"Revenue (£)\", row=2, col=1)\n",
    "        fig.update_xaxes(title_text=\"Day\", row=2, col=2)\n",
    "        fig.update_yaxes(title_text=\"Revenue (£)\", row=2, col=2)\n",
    "        fig.update_xaxes(title_text=\"Hour\", row=2, col=3)\n",
    "        fig.update_yaxes(title_text=\"Revenue (£)\", row=2, col=3)\n",
    "        \n",
    "        fig.show()\n",
    "\n",
    "# Attach function to button\n",
    "update_button.on_click(update_dashboard)\n",
    "\n",
    "print(\"Dashboard function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2156b35-7233-4c6b-89b6-8365045b2791",
   "metadata": {},
   "source": [
    "### 3.3 Display Interactive Dashboard\n",
    "\n",
    "Use the controls below to filter the data and click \"Update Dashboard\" to refresh the visualisations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75aba025-c640-490c-b1ed-8f1954366041",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display dashboard controls\n",
    "print(\"INTERACTIVE DASHBOARD CONTROLS\")\n",
    "print(\"=\"*50)\n",
    "print(\"Use the filters below to customize your view, then click 'Update Dashboard'\\n\")\n",
    "\n",
    "display(widgets.HBox([date_range, end_date_range]))\n",
    "display(widgets.HBox([country_filter, min_order_value]))\n",
    "display(update_button)\n",
    "display(output)\n",
    "\n",
    "# Trigger initial dashboard display\n",
    "update_dashboard(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28511c09-3308-4b84-b2ce-be80b586d5bf",
   "metadata": {},
   "source": [
    "### 3.4 Dashboard Usage Guide\n",
    "\n",
    "**How to use the dashboard:**\n",
    "\n",
    "1. **Select Date Range**: Choose start and end dates to focus on a specific time period\n",
    "2. **Choose Country**: Select 'All' for global view or a specific country for regional analysis\n",
    "3. **Set Minimum Order Value**: Adjust the slider to filter out smaller transactions\n",
    "4. **Click Update**: Press the \"Update Dashboard\" button to refresh all visualisations\n",
    "\n",
    "**Interactive Features:**\n",
    "- **Hover** over any chart element to see detailed values\n",
    "- **Zoom** by clicking and dragging on charts\n",
    "- **Pan** by holding shift and dragging\n",
    "- **Reset** view by double-clicking on charts\n",
    "\n",
    "**Business Questions the Dashboard Answers:**\n",
    "1. What is our total revenue and how many transactions occurred in a given period?\n",
    "2. How is revenue trending over time? Are there seasonal patterns?\n",
    "3. Which products are our top revenue generators?\n",
    "4. Which countries contribute most to our revenue?\n",
    "5. What days of the week and hours of the day see the highest sales?\n",
    "6. How do these patterns change when we focus on specific markets or time periods?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aab9c2b-4fc0-491b-99f4-9683b5ef893e",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "## 4. Summary and Key Insights\n",
    "\n",
    "### 4.1 Main Findings\n",
    "\n",
    "Through our comprehensive analysis of the Online Retail dataset, we have uncovered several important insights:\n",
    "\n",
    "**Data Quality:**\n",
    "- The original dataset contained 541,909 records, of which we retained approximately 75% after cleaning\n",
    "- Main quality issues included cancelled transactions, missing descriptions, and invalid quantities/prices\n",
    "- Missing CustomerID values (25% of records) limit customer-level analysis but don't prevent product and geographic insights\n",
    "\n",
    "**Sales Performance:**\n",
    "- Total revenue demonstrates the company's scale and market presence\n",
    "- Revenue trends show clear temporal patterns that can inform inventory and staffing decisions\n",
    "- The distribution of order values reveals typical customer purchasing behavior\n",
    "\n",
    "**Product Insights:**\n",
    "- A small number of products drive a large portion of revenue (Pareto principle)\n",
    "- Top products by quantity differ from top products by revenue, indicating different pricing strategies\n",
    "- Product performance data can guide inventory management and promotional strategies\n",
    "\n",
    "**Geographic Patterns:**\n",
    "- The UK dominates revenue as the home market, but international markets represent significant opportunities\n",
    "- Different countries may require tailored marketing and product strategies\n",
    "- Geographic diversity provides resilience against market-specific downturns\n",
    "\n",
    "**Temporal Patterns:**\n",
    "- Clear patterns emerge in sales by day of week and hour of day\n",
    "- These patterns can optimize operational decisions like staffing levels and promotional timing\n",
    "- Seasonal trends (if present in the data period) inform inventory planning\n",
    "\n",
    "### 4.2 Limitations\n",
    "\n",
    "**Data Limitations:**\n",
    "1. Missing CustomerID values prevent comprehensive customer lifetime value analysis\n",
    "2. Exclusion of cancelled transactions means we cannot analyze return patterns\n",
    "3. The dataset covers a specific time period and may not reflect current conditions\n",
    "4. No information about marketing campaigns or external factors that might explain sales patterns\n",
    "\n",
    "**Analysis Limitations:**\n",
    "1. Statistical outliers were retained, which may affect some aggregate measures\n",
    "2. Customer segmentation is limited by missing demographic data\n",
    "3. Product categorization would enhance analysis but is not available in the dataset\n",
    "4. Profit margins are unknown, so revenue doesn't necessarily indicate profitability\n",
    "\n",
    "### 4.3 Recommendations\n",
    "\n",
    "Based on this analysis, we recommend:\n",
    "\n",
    "1. **Improve Data Collection**: Reduce missing CustomerID values to enable better customer analytics\n",
    "2. **Focus on Top Products**: Ensure adequate inventory of high-revenue products\n",
    "3. **Optimize Timing**: Align staffing and promotions with peak hours and days\n",
    "4. **International Expansion**: Develop targeted strategies for high-potential international markets\n",
    "5. **Customer Retention**: Identify and nurture relationships with top customers\n",
    "6. **Further Analysis**: Conduct deeper analysis on customer segmentation, product bundling, and price optimization\n",
    "\n",
    "### 4.4 Conclusion\n",
    "\n",
    "This analysis has transformed raw transactional data into actionable business insights through systematic data cleaning, exploratory analysis, and interactive visualisation. The dashboard provides managers with a powerful tool to monitor performance, identify trends, and make data-driven decisions. While limitations exist, the insights gained provide a solid foundation for strategic planning and operational optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d068b18a-0997-4ae8-82d6-e9a5fa2d66be",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Appendix: AI Usage Declaration\n",
    "\n",
    "### AI Tools Used\n",
    "\n",
    "**Tools:** ChatGPT, GitHub\n",
    "\n",
    "**Purpose:** Code debugging, grammar checking, idea brainstorming\n",
    "\n",
    "**Prompts and Outputs:**\n",
    "\n",
    "```\n",
    "Prompt:\n",
    "\n",
    "I'm getting an error when trying to create an interactive dashboard with Plotly subplots \n",
    "and ipywidgets. The error message is:\n",
    "\n",
    "\"ValueError: Invalid property specified for object of type plotly.graph_objs.layout.Scene: \n",
    "'subplot_titles'\"\n",
    "\n",
    "Here's my code:\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=('KPIs', 'Revenue Trend', 'Top Products', \n",
    "                    'Top Countries', 'Day of Week', 'Hour of Day'),\n",
    "    specs=[[{'type': 'indicator'}, {'type': 'scatter'}, {'type': 'bar'}],\n",
    "           [{'type': 'bar'}, {'type': 'bar'}, {'type': 'bar'}]]\n",
    ")\n",
    "\n",
    "How can I fix this error?\n",
    "\n",
    "AI Output:\n",
    "\n",
    "The error occurs because you're mixing different subplot types, and Plotly has specific \n",
    "requirements for how subplot_titles work with different trace types. Here's the corrected \n",
    "approach:\n",
    "\n",
    "1. The 'indicator' type doesn't work well with subplot_titles in the same way as other \n",
    "   trace types.\n",
    "\n",
    "2. Try this corrected code:\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=(\n",
    "        'Key Performance Indicators',\n",
    "        'Revenue Trend Over Time',\n",
    "        'Top 10 Products by Revenue',\n",
    "        'Revenue by Country (Top 10)',\n",
    "        'Revenue by Day of Week',\n",
    "        'Revenue by Hour of Day'\n",
    "    ),\n",
    "    specs=[\n",
    "        [{'type': 'indicator'}, {'type': 'scatter'}, {'type': 'bar'}],\n",
    "        [{'type': 'bar'}, {'type': 'bar'}, {'type': 'bar'}]\n",
    "    ],\n",
    "    vertical_spacing=0.15,\n",
    "    horizontal_spacing=0.1\n",
    ")\n",
    "\n",
    "3. Make sure you're using the correct trace types when adding data to each subplot.\n",
    "\n",
    "4. For the indicator, you might need to handle it separately or use a different approach \n",
    "   for displaying KPIs.\n",
    "\n",
    "```\n",
    "\n",
    "### Reflection on AI Usage \n",
    "\n",
    "Throughout this data visualisation project, artificial intelligence tools played a significant supporting role in enhancing the quality and efficiency of my work, particularly in three key areas: code debugging, grammar checking, and idea brainstorming.\n",
    "\n",
    "In terms of code debugging, AI assistants proved invaluable when encountering errors in Python code, especially with Plotly's complex syntax for interactive dashboards. When facing issues with subplot configurations or widget interactions, I consulted AI tools to identify syntax errors and suggest corrections. This significantly reduced debugging time and helped me understand the underlying logic of the libraries, ultimately improving my programming skills rather than simply providing quick fixes.\n",
    "\n",
    "For grammar checking, AI tools helped ensure that my Markdown documentation maintained a professional and academic tone throughout the notebook. As a non-native English speaker, I particularly appreciated the assistance in refining technical explanations to make them accessible to non-technical stakeholders, which was a key requirement of the assignment. The tools helped identify awkward phrasing and suggested more concise alternatives without changing the meaning of my interpretations.\n",
    "\n",
    "Regarding idea brainstorming, AI assisted in exploring different approaches to data cleaning decisions and visualisation choices. When deciding how to handle missing CustomerID values or which chart types would best communicate specific insights, AI provided multiple perspectives that I could evaluate against business logic and best practices learned in the module.\n",
    "\n",
    "However, I remained critical of AI suggestions, validating all recommendations against course materials and data visualisation principles. Every final decision, interpretation, and insight in this assignment reflects my own analytical thinking and understanding of the data, with AI serving as a supportive tool rather than a replacement for critical thinking.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## References\n",
    "\n",
    "\n",
    "## Books\n",
    "\n",
    "McKinney, W. (2022) Python for Data Analysis: Data Wrangling with pandas, NumPy, and Jupyter. 3rd edn. Sebastopol, CA: O'Reilly Media.\n",
    "\n",
    "Knaflic, C.N. (2015) Storytelling with Data: A Data Visualization Guide for Business Professionals. Hoboken, NJ: John Wiley & Sons.\n",
    "\n",
    "Wilke, C.O. (2019) Fundamentals of Data Visualization: A Primer on Making Informative and Compelling Figures. Sebastopol, CA: O'Reilly Media.\n",
    "\n",
    "## Journal Articles\n",
    "\n",
    "Few, S. (2009) 'Now You See It: Simple Visualization Techniques for Quantitative Analysis', Analytics, June, pp. 1-5.\n",
    "\n",
    "Tufte, E.R. (2001) The Visual Display of Quantitative Information. 2nd edn. Cheshire, CT: Graphics Press.\n",
    "\n",
    "## Online Resources\n",
    "\n",
    "Plotly Technologies Inc. (2023) Plotly Python Graphing Library. Available at: https://plotly.com/python/ (Accessed: 20 November 2025 ).\n",
    "\n",
    "Pandas Development Team (2023) pandas: powerful Python data analysis toolkit. Available at: https://pandas.pydata.org/docs/ (Accessed: 18 November 2025 ).\n",
    "\n",
    "Matplotlib Development Team (2023) Matplotlib: Visualization with Python. Available at: https://matplotlib.org/ (Accessed: 19 November 2025 ).\n",
    "\n",
    "Seaborn Development Team (2023) seaborn: statistical data visualization. Available at: https://seaborn.pydata.org/ (Accessed: 19 November 2025 ).\n",
    "\n",
    "## Dataset\n",
    "\n",
    "Chen, D. (2015) Online Retail Dataset. UCI Machine Learning Repository. Available at: https://archive.ics.uci.edu/ml/datasets/Online+Retail (Accessed: 15 November 2025 )\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**End of Notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
